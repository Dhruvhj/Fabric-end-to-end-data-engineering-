# Fabric-end-to-end-data-engineering-

<img width="765" height="215" alt="Project Architecture" src="https://github.com/user-attachments/assets/4ffe0569-3a6f-4ca9-bf61-de0e0c6e5b77" />

This repository contains a complete end-to-end data engineering pipeline built using Microsoft Fabric Lakehouse, demonstrating real-world ETL, data modelling, and analytics workflows.

This project showcases my ability to build scalable and production-style data systems using modern tools across ingestion, transformation, orchestration, and reporting.

ğŸš€ Project Overview

This project processes raw sales data and transforms it into a clean Dimensional Model (Fact + Dimension tables) using:

Microsoft Fabric Lakehouse

Fabric Notebooks (PySpark)

Fabric Data Pipelines

SQL for DWH Modelling

Lakehouse Staging â†’ Silver â†’ Gold layers

ğŸ§± Project Architecture

Flow:

Raw CSV â†’ Staging Layer â†’ Transformations â†’ Fact Table â†’ Dimension Tables â†’ Analytics-Ready Layer

(Optional: I can generate an architecture diagram for you.)

ğŸ“‚ Repository Structure
data/                     â†’ Raw sales dataset  
sql/                      â†’ SQL scripts for schema + data load  
notebooks/                â†’ Fabric notebook (ETL & transformations)  
pipeline/                 â†’ Screenshots / JSON of the Fabric pipeline  
architecture/             â†’ System design diagrams  
ğŸ“Œ Files Included
ğŸ“ data/

sales.csv â€” Raw sales dataset used for ingestion

ğŸ“ sql/

SchemaFact&DimTablesQueryFabricDWH.sql
Contains Fact + Dimension table creation queries

LoadDataFromStagingLakehouseinFact&DimTables.sql
Inserts data into Fact & Dim tables from Staging

ğŸ“ notebooks/

PySpark notebook for Fabric transformations (optional to upload)

ğŸ¯ Key Features of This Project

âœ” Built entirely using Microsoft Fabric Lakehouse
âœ” Created staging & model schemas following DWH best practices
âœ” Loaded raw data â†’ cleaned â†’ modelled into Fact/Dim
âœ” Fabric pipeline executes all steps end-to-end
âœ” SQL-based star schema for reporting
âœ” Ready for BI tools (Power BI / Fabric Warehouse)

ğŸ› ï¸ Tools & Technologies Used

Microsoft Fabric Lakehouse

PySpark Notebooks

Fabric Data Pipelines

SQL (T-SQL)

Delta Tables

Data Modelling (Star Schema)

ğŸ“ˆ Results

This project demonstrates:

Data ingestion automation

Data modelling using Fact & Dimension tables

Production-style Fabric pipeline

Real-world data engineering workflow
